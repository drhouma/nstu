# Практическое занятие №2: Сортировка и поиск

__CPU__

*Имя модели*:                      Intel(R) Core(TM) i5-10210U CPU @ 1.60GHz

*Степпинг*:                        12

*CPU МГц*:                         2100.000

*CPU max MHz*:                     4200,0000

*CPU min MHz*:                     400,0000

*CPU(s)*:                          8

*On-line CPU(s) list*:             0-7

*Потоков на ядро*:                 2

## Часть 1: сортировка

__*Полученные в результате опытов данные*__
Количество чисел N=1000000=1e+6

| алгоритм / диапазон чисел       | N = 10000      | N = 100000         | N = 1000000        |
|:-------------------------------:|:--------------:|:------------------:|:------------------:|
| std::sort  / -1000 : 1000       | 0.00274786     | 0.032324           | 0.314826           |
| std::sort  / -50000000:50000000 | 0.00287955     | 0.0347168          | 0.45922            |
| count_sort / -1000:1000         | 0.000234329    | 0.00190227         | 0.0184182          |
| count_sort / -50000000:50000000 | 0.790755       | 0.784708           | 0.875442           |

* Выводы
    * __Когда есть массив, строго ограниченный малым диапазоном (-1000 : 1000), выгодно использовать count_sort, она более чем в 10 раз эффективнее std::sort__
    * __Когда массив ограничен диапазоном, размер которого больше или равен исходному массиву, алгоритм count_sort не выгоден__

## Часть 2: сортировка

__*Полученные в результате опытов данные*__
N = количество вставляемых элементов
M = количество строк по которым ведется поиск

| hash1            | N=10000, M=1000   | N=100000, M=10000  |N=1000000, M=100000 |
|:----------------:|:-----------------:|:------------------:|:------------------:|
| set              | 0.00329986        | 0.0337542          | 0.313661           |
| get              | 0.000296103       | 0.00287641         | 0.025194           |
| всего коллизий   | 0                 | 0                  | 4608               |

| hash2           | N=10000, M=1000    | N=100000, M=10000  |N=1000000, M=100000 |
|:----------------:|:-----------------:|:------------------:|:------------------:|
| set              | 0.00329813        | 0.0341628          | 0.343895           |
| get              | 0.000234761       | 0.00238776         | 0.0306051          |
| всего коллизий   | 0                 | 306                | 146533             |

| hash3            | N=10000, M=1000   | N=100000, M=10000  |N=1000000, M=100000 |
|:----------------:|:-----------------:|:------------------:|:------------------:|
| set              | 0.00294276       | 0.0335708           | 0.277744           |
| get              | 0.000210523      | 0.00238463          | 0.0385759          |
| всего коллизий   | 0                | 6481                | 288181             |


| std::map         | N=10000, M=1000   | N=100000, M=10000  |N=1000000, M=100000 |
|:----------------:|:-----------------:|:------------------:|:------------------:|
| set              | 0.00977337        | 0.106966           | 1.75129            |
| get              | 0.00774902        | 0.104641           | 1.46494            |


* Выводы
    * __Скорость работы целиком хэш таблицы полностью зависит от выбранной функции, и чем проще решение - тем лучше, однако такая функция должна раскидывать числа в большом диапазоне значений, иначе будет слишком много коллизий__
    * __На больших данных выгоднее всего использовать более сложные хэш функции, тк количество коллизий мало, и поиск элемента гораздо быстрее__